{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,make_scorer,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sn \n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= pd.read_csv('C:/Users/benedict halim/Desktop/Y2S2/CS3244/Project/Train_dataset.csv',index_col=0)\n",
    "train_data=train_data.drop(['date_x', 'date_actual_fail','serial_number','model'], axis=1)\n",
    "target=train_data['failure_actual_fail']\n",
    "X_train,X_test,y_train,y_test=train_test_split(train_data.drop(['failure_actual_fail'],axis='columns'),target,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#currently the data is unbalanced\n",
    "unique, count = np.unique(y_train, return_counts=True)\n",
    "y_train_dict_value_count = { k:v for (k,v) in zip(unique, count)}\n",
    "print(y_train_dict_value_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing the data via oversampling\n",
    "1. 1:4\n",
    "2. 1:3\n",
    "3. 1:2\n",
    "4. 1:1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 25041, 1: 649}\n",
      "{0: 25041, 1: 6260}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#balance to 1:1\n",
    "sm = SMOTE(random_state=3244,sampling_strategy = 1.0)\n",
    "x_train_over, y_train_over = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#balance to 1:4\n",
    "sm = SMOTE(random_state=3244,sampling_strategy = 0.25)\n",
    "x_train_over1, y_train_over1 = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#balance to 1:3 \n",
    "sm = SMOTE(random_state=3244,sampling_strategy = (1/3))\n",
    "x_train_over2, y_train_over2 = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#balance to 1:2\n",
    "sm = SMOTE(random_state=3244,sampling_strategy = 0.5)\n",
    "x_train_over3, y_train_over3 = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing the data via undersampling\n",
    "1. 1:4\n",
    "2. 1:3\n",
    "3. 1:2\n",
    "4. 1:1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1298, 1: 649}\n"
     ]
    }
   ],
   "source": [
    "#balance to 1:1\n",
    "sm = RandomUnderSampler(random_state=3244,sampling_strategy = 1.0)\n",
    "x_train_under, y_train_under = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#balance to 1:4\n",
    "sm = RandomUnderSampler(random_state=3244,sampling_strategy = 0.25)\n",
    "x_train_under1, y_train_under1 = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#balance to 1:3 \n",
    "sm = RandomUnderSampler(random_state=3244,sampling_strategy = (1/3))\n",
    "x_train_under2, y_train_under2 = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#balance to 1:2\n",
    "sm = RandomUnderSampler(random_state=3244,sampling_strategy = 0.5)\n",
    "x_train_under3, y_train_under3 = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "unique, count = np.unique(y_train_under3, return_counts=True)\n",
    "y_train_dict_value_count = { k:v for (k,v) in zip(unique, count)}\n",
    "print(y_train_dict_value_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_features_range = np.arange(1,6,1)\n",
    "n_estimators_range = np.arange(10,210,10)\n",
    "param_grid = dict(max_features=max_features_range, n_estimators=n_estimators_range)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5,scoring='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_features': array([1, 2, 3, 4, 5]),\n",
       "                         'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190, 200])},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.577990270187213"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = pd.concat([pd.DataFrame(grid.cv_results_[\"params\"]),pd.DataFrame(grid.cv_results_[\"mean_test_score\"], columns=[\"F1score\"])],axis=1)\n",
    "max(grid_results['F1score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" y_predicted=model.predict(X_test)\n",
    "cf_matrix = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "pyplot.show() \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcc91b7294ffb0df270c7186e0de16aad963ad10b0c4c1c40543d0ecce2b8460"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
